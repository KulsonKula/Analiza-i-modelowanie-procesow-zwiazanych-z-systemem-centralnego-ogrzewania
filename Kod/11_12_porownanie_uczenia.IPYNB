{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import glob \n",
    "import os \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "def build_and_compile_model_input(k):\n",
    "      model = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(512, activation='relu', input_shape=(k,)),\n",
    "          tf.keras.layers.Dense(256, activation='relu'),\n",
    "          tf.keras.layers.Dense(128, activation='relu'),\n",
    "          tf.keras.layers.Dense(64, activation='relu'),\n",
    "          tf.keras.layers.Dense(32, activation='relu'),\n",
    "          tf.keras.layers.Dense(1,activation='linear') \n",
    "    ])\n",
    "\n",
    "      model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss=\"mse\",\n",
    "                    metrics=['mae'])\n",
    "      return model\n",
    "\n",
    "scheduler = LearningRateScheduler(custom_scheduler)\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "callbacks = [scheduler, tensorboard]\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE=64\n",
    "\n",
    "DATASET_CALOSC=pd.read_csv('../Dane/data_nowe/dane_przetworzone/12_wybranych/calosc/calosc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3_plot=np.arange(0,100,100/1440) \n",
    "input_3=np.vstack((2*np.ones_like(input_3_plot, dtype=int),2*np.ones_like(input_3_plot, dtype=int),input_3_plot)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pora_roku</th>\n",
       "      <th>Dzien_tygodnia</th>\n",
       "      <th>Czas_dnia</th>\n",
       "      <th>Przeplyw</th>\n",
       "      <th>Tyg_zuzycie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096635</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096636</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096637</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096638</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096639</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1185.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2096640 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pora_roku  Dzien_tygodnia  Czas_dnia  Przeplyw  Tyg_zuzycie\n",
       "0              2.0             1.0   0.000000       0.0       627.50\n",
       "1              2.0             1.0   0.000694       0.0       627.50\n",
       "2              2.0             1.0   0.001389       0.0       627.50\n",
       "3              2.0             1.0   0.002083       0.0       627.50\n",
       "4              2.0             1.0   0.002778       0.0       627.50\n",
       "...            ...             ...        ...       ...          ...\n",
       "2096635        1.0             7.0   0.996528       0.0      1185.25\n",
       "2096636        1.0             7.0   0.997222       0.0      1185.25\n",
       "2096637        1.0             7.0   0.997917       0.0      1185.25\n",
       "2096638        1.0             7.0   0.998611       0.0      1185.25\n",
       "2096639        1.0             7.0   0.999306       0.0      1185.25\n",
       "\n",
       "[2096640 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_CALOSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 3 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26208/26208 [==============================] - 54s 2ms/step - loss: 0.5653 - mae: 0.1727 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5629 - mae: 0.1713 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5628 - mae: 0.1711 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5627 - mae: 0.1711 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5625 - mae: 0.1710 - lr: 9.0484e-04\n",
      "Epoch 6/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5624 - mae: 0.1707 - lr: 8.1873e-04\n",
      "Epoch 7/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5623 - mae: 0.1705 - lr: 7.4082e-04\n",
      "Epoch 8/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5622 - mae: 0.1704 - lr: 6.7032e-04\n",
      "Epoch 9/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5622 - mae: 0.1703 - lr: 6.0653e-04\n",
      "Epoch 10/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5621 - mae: 0.1702 - lr: 5.4881e-04\n",
      "Epoch 11/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5620 - mae: 0.1701 - lr: 4.9659e-04\n",
      "Epoch 12/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5621 - mae: 0.1705 - lr: 4.4933e-04\n",
      "Epoch 13/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5622 - mae: 0.1697 - lr: 4.0657e-04\n",
      "Epoch 14/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5619 - mae: 0.1699 - lr: 3.6788e-04\n",
      "Epoch 15/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5618 - mae: 0.1698 - lr: 3.3287e-04\n",
      "Epoch 16/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5617 - mae: 0.1697 - lr: 3.0119e-04\n",
      "Epoch 17/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5617 - mae: 0.1696 - lr: 2.7253e-04\n",
      "Epoch 18/50\n",
      "26208/26208 [==============================] - 54s 2ms/step - loss: 0.5617 - mae: 0.1695 - lr: 2.4660e-04\n",
      "Epoch 19/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5617 - mae: 0.1694 - lr: 2.2313e-04\n",
      "Epoch 20/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5616 - mae: 0.1694 - lr: 2.0190e-04\n",
      "Epoch 21/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5615 - mae: 0.1691 - lr: 1.8268e-04\n",
      "Epoch 22/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5613 - mae: 0.1695 - lr: 1.6530e-04\n",
      "Epoch 23/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5613 - mae: 0.1690 - lr: 1.4957e-04\n",
      "Epoch 24/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5612 - mae: 0.1691 - lr: 1.3534e-04\n",
      "Epoch 25/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5611 - mae: 0.1691 - lr: 1.2246e-04\n",
      "Epoch 26/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5611 - mae: 0.1688 - lr: 1.1080e-04\n",
      "Epoch 27/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5609 - mae: 0.1689 - lr: 1.0026e-04\n",
      "Epoch 28/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5608 - mae: 0.1689 - lr: 9.0718e-05\n",
      "Epoch 29/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5607 - mae: 0.1688 - lr: 8.2085e-05\n",
      "Epoch 30/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5607 - mae: 0.1686 - lr: 7.4273e-05\n",
      "Epoch 31/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5605 - mae: 0.1685 - lr: 6.7205e-05\n",
      "Epoch 32/50\n",
      "26208/26208 [==============================] - 52s 2ms/step - loss: 0.5603 - mae: 0.1685 - lr: 6.0810e-05\n",
      "Epoch 33/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5602 - mae: 0.1684 - lr: 5.5023e-05\n",
      "Epoch 34/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5601 - mae: 0.1683 - lr: 4.9787e-05\n",
      "Epoch 35/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5601 - mae: 0.1685 - lr: 4.5049e-05\n",
      "Epoch 36/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5600 - mae: 0.1685 - lr: 4.0762e-05\n",
      "Epoch 37/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5600 - mae: 0.1681 - lr: 3.6883e-05\n",
      "Epoch 38/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5599 - mae: 0.1681 - lr: 3.3373e-05\n",
      "Epoch 39/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5598 - mae: 0.1684 - lr: 3.0197e-05\n",
      "Epoch 40/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5598 - mae: 0.1682 - lr: 2.7324e-05\n",
      "Epoch 41/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5598 - mae: 0.1679 - lr: 2.4723e-05\n",
      "Epoch 42/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5597 - mae: 0.1681 - lr: 2.2371e-05\n",
      "Epoch 43/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5597 - mae: 0.1682 - lr: 2.0242e-05\n",
      "Epoch 44/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5597 - mae: 0.1680 - lr: 1.8316e-05\n",
      "Epoch 45/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5596 - mae: 0.1680 - lr: 1.6573e-05\n",
      "Epoch 46/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5597 - mae: 0.1680 - lr: 1.4996e-05\n",
      "Epoch 47/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5596 - mae: 0.1681 - lr: 1.3569e-05\n",
      "Epoch 48/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5596 - mae: 0.1681 - lr: 1.2277e-05\n",
      "Epoch 49/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5596 - mae: 0.1679 - lr: 1.1109e-05\n",
      "Epoch 50/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5595 - mae: 0.1680 - lr: 1.0052e-05\n",
      "INFO:tensorflow:Assets written to: ../Modele/11_12_testowanie/model_calosc_bez_dodatku\\assets\n"
     ]
    }
   ],
   "source": [
    "dataset = DATASET_CALOSC\n",
    "dataset=dataset.drop(columns=\"Tyg_zuzycie\")\n",
    "dataset['Czas_dnia'] = dataset['Czas_dnia'] * 100\n",
    "x=dataset.drop(columns=\"Przeplyw\")\n",
    "y=dataset.drop(columns=\"Dzien_tygodnia\")\n",
    "y=y.drop(columns=\"Czas_dnia\")\n",
    "y=y.drop(columns=\"Pora_roku\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model_calosc_danych_bez_dodatku =build_and_compile_model_input(3)\n",
    "model_calosc_danych_bez_dodatku.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)\n",
    "model_calosc_danych_bez_dodatku.save(\"../Modele/11_12_testowanie/model_calosc_bez_dodatku\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 4 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.9482 - mae: 0.2140 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5638 - mae: 0.1693 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5657 - mae: 0.1702 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 9.0484e-04\n",
      "Epoch 6/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 8.1873e-04\n",
      "Epoch 7/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 7.4082e-04\n",
      "Epoch 8/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 6.7032e-04\n",
      "Epoch 9/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 6.0653e-04\n",
      "Epoch 10/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 5.4881e-04\n",
      "Epoch 11/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1702 - lr: 4.9659e-04\n",
      "Epoch 12/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 4.4933e-04\n",
      "Epoch 13/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1702 - lr: 4.0657e-04\n",
      "Epoch 14/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 3.6788e-04\n",
      "Epoch 15/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 3.3287e-04\n",
      "Epoch 16/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 3.0119e-04\n",
      "Epoch 17/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 2.7253e-04\n",
      "Epoch 18/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 2.4660e-04\n",
      "Epoch 19/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 2.2313e-04\n",
      "Epoch 20/50\n",
      "26208/26208 [==============================] - 51s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 2.0190e-04\n",
      "Epoch 21/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 1.8268e-04\n",
      "Epoch 22/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 1.6530e-04\n",
      "Epoch 23/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1705 - lr: 1.4957e-04\n",
      "Epoch 24/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5656 - mae: 0.1701 - lr: 1.3534e-04\n",
      "Epoch 25/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5656 - mae: 0.1704 - lr: 1.2246e-04\n",
      "Epoch 26/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 1.1080e-04\n",
      "Epoch 27/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1701 - lr: 1.0026e-04\n",
      "Epoch 28/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1705 - lr: 9.0718e-05\n",
      "Epoch 29/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1704 - lr: 8.2085e-05\n",
      "Epoch 30/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1701 - lr: 7.4273e-05\n",
      "Epoch 31/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1704 - lr: 6.7205e-05\n",
      "Epoch 32/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 6.0810e-05\n",
      "Epoch 33/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1701 - lr: 5.5023e-05\n",
      "Epoch 34/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1700 - lr: 4.9787e-05\n",
      "Epoch 35/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 4.5049e-05\n",
      "Epoch 36/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1703 - lr: 4.0762e-05\n",
      "Epoch 37/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1702 - lr: 3.6883e-05\n",
      "Epoch 38/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5656 - mae: 0.1703 - lr: 3.3373e-05\n",
      "Epoch 39/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5657 - mae: 0.1702 - lr: 3.0197e-05\n",
      "Epoch 40/50\n",
      "26208/26208 [==============================] - 46s 2ms/step - loss: 0.5657 - mae: 0.1700 - lr: 2.7324e-05\n",
      "Epoch 41/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1705 - lr: 2.4723e-05\n",
      "Epoch 42/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1701 - lr: 2.2371e-05\n",
      "Epoch 43/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1701 - lr: 2.0242e-05\n",
      "Epoch 44/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5657 - mae: 0.1704 - lr: 1.8316e-05\n",
      "Epoch 45/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5657 - mae: 0.1699 - lr: 1.6573e-05\n",
      "Epoch 46/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1705 - lr: 1.4996e-05\n",
      "Epoch 47/50\n",
      "26208/26208 [==============================] - 48s 2ms/step - loss: 0.5656 - mae: 0.1701 - lr: 1.3569e-05\n",
      "Epoch 48/50\n",
      "26208/26208 [==============================] - 47s 2ms/step - loss: 0.5657 - mae: 0.1701 - lr: 1.2277e-05\n",
      "Epoch 49/50\n",
      "26208/26208 [==============================] - 50s 2ms/step - loss: 0.5657 - mae: 0.1704 - lr: 1.1109e-05\n",
      "Epoch 50/50\n",
      "26208/26208 [==============================] - 49s 2ms/step - loss: 0.5657 - mae: 0.1702 - lr: 1.0052e-05\n",
      "INFO:tensorflow:Assets written to: ../Modele/11_12_testowanie/model_calosc_z_dodatku\\assets\n"
     ]
    }
   ],
   "source": [
    "dataset = DATASET_CALOSC\n",
    "dataset['Czas_dnia'] = dataset['Czas_dnia'] * 100\n",
    "x=dataset.drop(columns=\"Przeplyw\")\n",
    "y=dataset.drop(columns=\"Dzien_tygodnia\")\n",
    "y=y.drop(columns=\"Czas_dnia\")\n",
    "y=y.drop(columns=\"Tyg_zuzycie\")\n",
    "y=y.drop(columns=\"Pora_roku\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model_calosc_danych_z_dodatku =build_and_compile_model_input(4)\n",
    "model_calosc_danych_z_dodatku.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)\n",
    "model_calosc_danych_z_dodatku.save(\"../Modele/11_12_testowanie/model_calosc_z_dodatku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    data=data.drop(columns=\"Tyg_zuzycie\")\n",
    "    data['Czas_dnia'] = data['Czas_dnia'] * 100\n",
    "    x=data.drop(columns=\"Przeplyw\")\n",
    "    y=data.drop(columns=\"Dzien_tygodnia\")\n",
    "    y=y.drop(columns=\"Czas_dnia\")\n",
    "    y=y.drop(columns=\"Pora_roku\")\n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.7101 - mae: 0.1708 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.7005 - mae: 0.1636 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6998 - mae: 0.1635 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6998 - mae: 0.1643 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6999 - mae: 0.1634 - lr: 9.0484e-04\n",
      "Epoch 6/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6996 - mae: 0.1641 - lr: 8.1873e-04\n",
      "Epoch 7/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6994 - mae: 0.1639 - lr: 7.4082e-04\n",
      "Epoch 8/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6990 - mae: 0.1648 - lr: 6.7032e-04\n",
      "Epoch 9/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6988 - mae: 0.1635 - lr: 6.0653e-04\n",
      "Epoch 10/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6985 - mae: 0.1669 - lr: 5.4881e-04\n",
      "Epoch 11/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6982 - mae: 0.1637 - lr: 4.9659e-04\n",
      "Epoch 12/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6979 - mae: 0.1654 - lr: 4.4933e-04\n",
      "Epoch 13/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6969 - mae: 0.1629 - lr: 4.0657e-04\n",
      "Epoch 14/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6966 - mae: 0.1636 - lr: 3.6788e-04\n",
      "Epoch 15/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6952 - mae: 0.1640 - lr: 3.3287e-04\n",
      "Epoch 16/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6925 - mae: 0.1624 - lr: 3.0119e-04\n",
      "Epoch 17/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6910 - mae: 0.1625 - lr: 2.7253e-04\n",
      "Epoch 18/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6889 - mae: 0.1622 - lr: 2.4660e-04\n",
      "Epoch 19/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6880 - mae: 0.1627 - lr: 2.2313e-04\n",
      "Epoch 20/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6872 - mae: 0.1608 - lr: 2.0190e-04\n",
      "Epoch 21/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6870 - mae: 0.1621 - lr: 1.8268e-04\n",
      "Epoch 22/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6858 - mae: 0.1613 - lr: 1.6530e-04\n",
      "Epoch 23/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6847 - mae: 0.1625 - lr: 1.4957e-04\n",
      "Epoch 24/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6843 - mae: 0.1603 - lr: 1.3534e-04\n",
      "Epoch 25/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6834 - mae: 0.1602 - lr: 1.2246e-04\n",
      "Epoch 26/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6826 - mae: 0.1602 - lr: 1.1080e-04\n",
      "Epoch 27/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6819 - mae: 0.1611 - lr: 1.0026e-04\n",
      "Epoch 28/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6816 - mae: 0.1601 - lr: 9.0718e-05\n",
      "Epoch 29/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6813 - mae: 0.1585 - lr: 8.2085e-05\n",
      "Epoch 30/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6805 - mae: 0.1582 - lr: 7.4273e-05\n",
      "Epoch 31/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6804 - mae: 0.1597 - lr: 6.7205e-05\n",
      "Epoch 32/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6796 - mae: 0.1597 - lr: 6.0810e-05\n",
      "Epoch 33/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6794 - mae: 0.1591 - lr: 5.5023e-05\n",
      "Epoch 34/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6786 - mae: 0.1576 - lr: 4.9787e-05\n",
      "Epoch 35/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6787 - mae: 0.1602 - lr: 4.5049e-05\n",
      "Epoch 36/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6782 - mae: 0.1573 - lr: 4.0762e-05\n",
      "Epoch 37/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6778 - mae: 0.1585 - lr: 3.6883e-05\n",
      "Epoch 38/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6777 - mae: 0.1579 - lr: 3.3373e-05\n",
      "Epoch 39/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6773 - mae: 0.1584 - lr: 3.0197e-05\n",
      "Epoch 40/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6772 - mae: 0.1589 - lr: 2.7324e-05\n",
      "Epoch 41/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6770 - mae: 0.1581 - lr: 2.4723e-05\n",
      "Epoch 42/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6767 - mae: 0.1575 - lr: 2.2371e-05\n",
      "Epoch 43/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6766 - mae: 0.1573 - lr: 2.0242e-05\n",
      "Epoch 44/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6765 - mae: 0.1579 - lr: 1.8316e-05\n",
      "Epoch 45/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6762 - mae: 0.1578 - lr: 1.6573e-05\n",
      "Epoch 46/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6760 - mae: 0.1579 - lr: 1.4996e-05\n",
      "Epoch 47/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6759 - mae: 0.1578 - lr: 1.3569e-05\n",
      "Epoch 48/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6758 - mae: 0.1569 - lr: 1.2277e-05\n",
      "Epoch 49/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6757 - mae: 0.1578 - lr: 1.1109e-05\n",
      "Epoch 50/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.6756 - mae: 0.1577 - lr: 1.0052e-05\n",
      "INFO:tensorflow:Assets written to: ../Modele/11_12_testowanie/model_calosc_z_dodatku_1\\assets\n",
      "45/45 [==============================] - 0s 899us/step\n",
      "45/45 [==============================] - 0s 912us/step\n",
      "45/45 [==============================] - 0s 888us/step\n",
      "Epoch 1/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1260 - mae: 0.0760 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1165 - mae: 0.0592 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1163 - mae: 0.0563 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1164 - mae: 0.0550 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1164 - mae: 0.0546 - lr: 9.0484e-04\n",
      "Epoch 6/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1163 - mae: 0.0542 - lr: 8.1873e-04\n",
      "Epoch 7/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1163 - mae: 0.0547 - lr: 7.4082e-04\n",
      "Epoch 8/50\n",
      "2016/2016 [==============================] - 4s 2ms/step - loss: 0.1163 - mae: 0.0543 - lr: 6.7032e-04\n",
      "Epoch 9/50\n",
      "1238/2016 [=================>............] - ETA: 1s - loss: 0.1086 - mae: 0.0536"
     ]
    }
   ],
   "source": [
    "fig_1, axs_1 = plt.subplots(2, 7,figsize=(25, 6))\n",
    "\n",
    "fig_2, axs_2 = plt.subplots(2, 7,figsize=(25, 6))\n",
    "\n",
    "path = os.getcwd() \n",
    "csv_files = glob.glob(os.path.join(path, '../Dane/data_nowe/dane_przetworzone/12_wybranych/*.csv')) \n",
    "i=0;\n",
    "k=0;\n",
    "for f in csv_files: \n",
    "    dataset = pd.read_csv(f) \n",
    "    [x,y]=prep_data(dataset) \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model_temp =build_and_compile_model_input(3)\n",
    "    model_temp.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)\n",
    "    model_temp.save(\"../Modele/11_12_testowanie/model_calosc_z_dodatku_\"+str((i+1)*(k+1)))\n",
    "    output_1=model_temp.predict(input_3)\n",
    "\n",
    "    axs_1[k,i].plot(input_3_plot, output_1.reshape(1440))\n",
    "    output_2=model_calosc_danych_bez_dodatku.predict(input_3)\n",
    "    axs_1[k,i].plot(input_3_plot, output_2.reshape(1440))\n",
    "    axs_1[k,i].set_xlim(0, 100)\n",
    "    mse=mean_squared_error(output_1,output_2)\n",
    "    axs_1[k,i].set_title(\"mse: \"+ str(mse))\n",
    "\n",
    "    result = dataset.loc[(dataset['Dzien_tygodnia'] == 2) & (dataset['Pora_roku'] == 2),\"Tyg_zuzycie\"]\n",
    "    input_4=np.vstack((2*np.ones_like(input_3_plot, dtype=int), 2*np.ones_like(input_3_plot, dtype=int), input_3_plot, result.mean()*np.ones_like(input_3_plot, dtype=int))).T\n",
    "    axs_2[k,i].plot(input_3_plot, output_1.reshape(1440))\n",
    "    output_2=model_calosc_danych_z_dodatku.predict(input_4)\n",
    "    axs_2[k,i].plot(input_3_plot, output_2.reshape(1440))\n",
    "    axs_2[k,i].set_xlim(0, 100)\n",
    "    mse=mean_squared_error(output_1,output_2)\n",
    "    axs_2[k,i].set_title(\"mse: \"+str(mse))\n",
    "\n",
    "    i+=1\n",
    "    if i==7:\n",
    "        k=1\n",
    "        i=0\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
